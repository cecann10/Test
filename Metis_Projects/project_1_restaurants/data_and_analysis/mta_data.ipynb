{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will do bulk-pull of MTA data for \n",
    "# multiple weeks.  Function used in\n",
    "# get_yearly_data_station_only(), \n",
    "# get_yearly_data_fulton(), \n",
    "# get_yearly_data_chambers():\n",
    "\n",
    "def get_data(week_nums):\n",
    "    '''\n",
    "    Input: List of dates in format YYMMDD that \n",
    "    are ending of MTA raw data files.\n",
    "    Output: Concatenated datframe of MTA dates\n",
    "    inputed.\n",
    "    '''\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used in\n",
    "# get_yearly_data_station_only(), \n",
    "# get_yearly_data_fulton(), \n",
    "# get_yearly_data_chambers():\n",
    "\n",
    "def get_day_entry_counts(row, max_counter):\n",
    "    '''\n",
    "    Input: Raw entries for MTA data.\n",
    "    Output: Daily numbers for entries in MTA data.\n",
    "    '''\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter > max_counter:\n",
    "        return 0\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used in\n",
    "# get_yearly_data_station_only(), \n",
    "# get_yearly_data_fulton(), \n",
    "# get_yearly_data_chambers():\n",
    "\n",
    "def get_day_exit_counts(row, max_counter):\n",
    "    '''\n",
    "    Input: Raw entries for MTA data.\n",
    "    Output: Daily numbers for entries in MTA data.\n",
    "    '''\n",
    "    counter = row[\"EXITS\"] - row[\"PREV_EXITS\"]\n",
    "    if counter < 0:\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        counter = min(row[\"EXITS\"], row[\"PREV_EXITS\"])\n",
    "    if counter > max_counter:\n",
    "        return 0\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Master' function to get data for target stations\n",
    "# that are not line-dependent\n",
    "\n",
    "\n",
    "def get_yearly_data_station_only(list_of_weeks):\n",
    "    '''\n",
    "    Input: A list of dates that match the end of the \n",
    "    MTA raw data files that you want to pull from in the \n",
    "    format YYMMDD, such as \"200104.\"\n",
    "    \n",
    "    Output: will be a dataframe that lists only data\n",
    "    for the stations: Times Sq, Grand Central, Lexington,\n",
    "    34 St. Herald, St.Union, 59 St Columbus, and Penn\n",
    "    Station.  For those stations will also see:\n",
    "    1. Date\n",
    "    2. Daily Entries\n",
    "    3. Daily Exits\n",
    "    4. Week Of date\n",
    "    5. Total Traffic (Entries + Exits)\n",
    "    '''\n",
    "    df = get_data(list_of_weeks)\n",
    "    \n",
    "    # create df with only stations focusing on\n",
    "    df_stations = df[(df.STATION == 'TIMES SQ-42 ST')\n",
    "                     |(df.STATION == 'GRD CNTRL-42 ST')\n",
    "                     |(df.STATION == 'LEXINGTON AV/53')\n",
    "                     |(df.STATION == '34 ST-HERALD SQ')\n",
    "                     |(df.STATION == '14 ST-UNION SQ')\n",
    "                     |(df.STATION == '59 ST COLUMBUS')\n",
    "                     |(df.STATION == '34 ST-PENN STA')]\n",
    "\n",
    "\n",
    "    df_stations.rename(columns={df_stations.columns[10]: 'EXITS'}\n",
    "                       , inplace=True)\n",
    "\n",
    "    \n",
    "    # find first entry for entries and exits\n",
    "    day_counts_df = df_stations.groupby(['C/A','UNIT','SCP','STATION','DATE']\n",
    "                                    ,as_index=False)[['ENTRIES','EXITS']].first()\n",
    "    \n",
    "    # get the ENTRY daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_ENTRY_DATE', 'PREV_ENTRIES']] = (day_counts_df\n",
    "                                                          .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'ENTRIES']\n",
    "                                                          .apply(lambda grp: grp.shift(1)))\n",
    "   \n",
    "    # get the EXIT daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_EXIT_DATE', 'PREV_EXITS']] = (day_counts_df\n",
    "                                                       .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'EXITS']\n",
    "                                                       .apply(lambda grp: grp.shift(1)))\n",
    "    \n",
    "    \n",
    "    # drop nan where applicable in new previous date columns for entries & exits\n",
    "    day_counts_df.dropna(subset=['PREV_ENTRY_DATE'], inplace=True)\n",
    "    day_counts_df.dropna(subset=['PREV_EXIT_DATE'], inplace=True)\n",
    "    \n",
    "\n",
    "    #create new columns for daily entries and daily exits\n",
    "    day_counts_df[\"DAILY_ENTRIES\"] = (day_counts_df\n",
    "                                            .apply(get_day_entry_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    day_counts_df[\"DAILY_EXITS\"] = (day_counts_df\n",
    "                                    .apply(get_day_exit_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    \n",
    "    # set datetime data\n",
    "    day_counts_df['DATE'] = pd.to_datetime(day_counts_df['DATE'])\n",
    "    \n",
    "    \n",
    "    # get the daily summary data of station\n",
    "    daily_sum_stations = day_counts_df.groupby(\n",
    "        ['STATION','DATE'])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index()\n",
    "    \n",
    "    # get the fist day of the week & place in new 'WeekOf' column\n",
    "    daily_sum_stations['weekday'] = daily_sum_stations['DATE'].dt.dayofweek\n",
    "    daily_sum_stations['WeekOf'] = daily_sum_stations['DATE']\n",
    "    daily_sum_stations.loc[daily_sum_stations.weekday != 0, 'WeekOf'] = ''\n",
    "    daily_sum_stations = daily_sum_stations.replace('',np.nan).ffill()\n",
    "    daily_sum_stations['WeekOf'] = pd.to_datetime(daily_sum_stations['WeekOf']).dt.date\n",
    "#     daily_sum_stations = daily_sum_stations[daily_sum_stations.WeekOf.notnull()]\n",
    "    \n",
    "    # get total Traffic (= entries + exits) & place in new 'TotalTraffic' column\n",
    "    daily_sum_stations['TotalTraffic'] = (daily_sum_stations['DAILY_ENTRIES'] \n",
    "                                          + daily_sum_stations['DAILY_EXITS'])\n",
    "    \n",
    "    \n",
    "    return daily_sum_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_data_fulton(list_of_weeks):\n",
    "    '''\n",
    "    Input: A list of dates that match the end of the \n",
    "    MTA raw data files that you want to pull from in the \n",
    "    format YYMMDD, such as \"200104.\"\n",
    "    \n",
    "    Output: will be a dataframe that lists only data\n",
    "    for the Fulton St's lines: 'ACJZ2345'\n",
    "    and '2345ACJZ'.  Data for two lines will be \n",
    "    combined under Fulton as one.  Will also see:\n",
    "    1. Date\n",
    "    2. Daily Entries\n",
    "    3. Daily Exits\n",
    "    4. Week Of date\n",
    "    5. Total Traffic (Entries + Exits)\n",
    "    '''\n",
    "    df = get_data(list_of_weeks)\n",
    "    \n",
    "    # create df with only stations focusing on\n",
    "    df_stations = df[(df.STATION == \"FULTON ST\")]\n",
    "    # get the lines we need for \"FULTON ST\"\n",
    "    df_stations = df_stations[(df_stations.LINENAME == 'ACJZ2345')\n",
    "                                     |(df_stations.LINENAME == '2345ACJZ')]\n",
    "\n",
    "    df_stations.rename(columns={df_stations.columns[10]: 'EXITS'}\n",
    "                       , inplace=True)\n",
    "\n",
    "    \n",
    "    # find first entry for entries and exits\n",
    "    day_counts_df = df_stations.groupby(['C/A','UNIT','SCP','STATION','DATE']\n",
    "                                    ,as_index=False)[['ENTRIES','EXITS']].first()\n",
    "    \n",
    "    # get the ENTRY daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_ENTRY_DATE', 'PREV_ENTRIES']] = (day_counts_df\n",
    "                                                          .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'ENTRIES']\n",
    "                                                          .apply(lambda grp: grp.shift(1)))\n",
    "   \n",
    "    # get the EXIT daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_EXIT_DATE', 'PREV_EXITS']] = (day_counts_df\n",
    "                                                       .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'EXITS']\n",
    "                                                       .apply(lambda grp: grp.shift(1)))\n",
    "    \n",
    "    \n",
    "    # drop nan where applicable in new previous date columns for entries & exits\n",
    "    day_counts_df.dropna(subset=['PREV_ENTRY_DATE'], inplace=True)\n",
    "    day_counts_df.dropna(subset=['PREV_EXIT_DATE'], inplace=True)\n",
    "    \n",
    "\n",
    "    #create new columns for daily entries and daily exits\n",
    "    day_counts_df[\"DAILY_ENTRIES\"] = (day_counts_df\n",
    "                                            .apply(get_day_entry_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    day_counts_df[\"DAILY_EXITS\"] = (day_counts_df\n",
    "                                    .apply(get_day_exit_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    \n",
    "    # set datetime data\n",
    "    day_counts_df['DATE'] = pd.to_datetime(day_counts_df['DATE'])\n",
    "    \n",
    "    \n",
    "    # get the daily summary data of station\n",
    "    daily_sum_stations = day_counts_df.groupby(\n",
    "        ['STATION','DATE'])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index()\n",
    "    \n",
    "    # get the fist day of the week & place in new 'WeekOf' column\n",
    "    daily_sum_stations['weekday'] = daily_sum_stations['DATE'].dt.dayofweek\n",
    "    daily_sum_stations['WeekOf'] = daily_sum_stations['DATE']\n",
    "    daily_sum_stations.loc[daily_sum_stations.weekday != 0, 'WeekOf'] = ''\n",
    "    daily_sum_stations = daily_sum_stations.replace('',np.nan).ffill()\n",
    "    daily_sum_stations['WeekOf'] = pd.to_datetime(daily_sum_stations['WeekOf']).dt.date\n",
    "    daily_sum_stations = daily_sum_stations[daily_sum_stations.WeekOf.notnull()]\n",
    "    \n",
    "    # get total Traffic (= entries + exits) & place in new 'TotalTraffic' column\n",
    "    daily_sum_stations['TotalTraffic'] = (daily_sum_stations['DAILY_ENTRIES'] \n",
    "                                          + daily_sum_stations['DAILY_EXITS'])\n",
    "    \n",
    "    \n",
    "    return daily_sum_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_data_chambers(list_of_weeks):\n",
    "    '''\n",
    "    Input: A list of dates that match the end of the \n",
    "    MTA raw data files that you want to pull from in the \n",
    "    format YYMMDD, such as \"200104.\"\n",
    "    \n",
    "    Output: will be a dataframe that lists only data\n",
    "    for the Chambers' lines: 'JZ456'and 'ACE23'.  Data \n",
    "    for two lines will be combined under Chambers as one.  \n",
    "    Will also see:\n",
    "    1. Date\n",
    "    2. Daily Entries\n",
    "    3. Daily Exits\n",
    "    4. Week Of date\n",
    "    5. Total Traffic (Entries + Exits)\n",
    "    '''\n",
    "    df = get_data(list_of_weeks)\n",
    "    \n",
    "    # create df with only stations focusing on\n",
    "    df_stations = df[(df.STATION == \"CHAMBERS ST\")]\n",
    "    # get the lines we need for \"CHAMBERS ST\"\n",
    "    df_stations = df_stations[(df_stations.LINENAME == 'JZ456')\n",
    "                                     |(df_stations.LINENAME == 'ACE23')]\n",
    "\n",
    "    df_stations.rename(columns={df_stations.columns[10]: 'EXITS'}\n",
    "                       , inplace=True)\n",
    "\n",
    "    \n",
    "    # find first entry for entries and exits\n",
    "    day_counts_df = df_stations.groupby(['C/A','UNIT','SCP','STATION','DATE']\n",
    "                                    ,as_index=False)[['ENTRIES','EXITS']].first()\n",
    "    \n",
    "    # get the ENTRY daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_ENTRY_DATE', 'PREV_ENTRIES']] = (\n",
    "        day_counts_df\n",
    "        .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'ENTRIES']\n",
    "        .apply(lambda grp: grp.shift(1)))\n",
    "   \n",
    "    # get the EXIT daily summary data of each turnstile\n",
    "    day_counts_df[['PREV_EXIT_DATE', 'PREV_EXITS']] = (\n",
    "        day_counts_df\n",
    "        .groupby(['C/A', 'UNIT', 'SCP', 'STATION'])['DATE', 'EXITS']\n",
    "        .apply(lambda grp: grp.shift(1)))\n",
    "    \n",
    "    \n",
    "    # drop nan where applicable in new previous date columns for entries & exits\n",
    "    day_counts_df.dropna(subset=['PREV_ENTRY_DATE'], inplace=True)\n",
    "    day_counts_df.dropna(subset=['PREV_EXIT_DATE'], inplace=True)\n",
    "    \n",
    "\n",
    "    #create new columns for daily entries and daily exits\n",
    "    day_counts_df[\"DAILY_ENTRIES\"] = (\n",
    "        day_counts_df\n",
    "        .apply(get_day_entry_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    day_counts_df[\"DAILY_EXITS\"] = (\n",
    "        day_counts_df\n",
    "        .apply(get_day_exit_counts, axis=1, max_counter=100_000))\n",
    "    \n",
    "    \n",
    "    # set datetime data\n",
    "    day_counts_df['DATE'] = pd.to_datetime(day_counts_df['DATE'])\n",
    "    \n",
    "    \n",
    "    # get the daily summary data of station\n",
    "    daily_sum_stations = day_counts_df.groupby(\n",
    "        ['STATION','DATE'])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index()\n",
    "    \n",
    "    # get the fist day of the week & place in new 'WeekOf' column\n",
    "    daily_sum_stations['weekday'] = daily_sum_stations['DATE'].dt.dayofweek\n",
    "    daily_sum_stations['WeekOf'] = daily_sum_stations['DATE']\n",
    "    daily_sum_stations.loc[daily_sum_stations.weekday != 0, 'WeekOf'] = ''\n",
    "    daily_sum_stations = daily_sum_stations.replace('',np.nan).ffill()\n",
    "    daily_sum_stations['WeekOf'] = pd.to_datetime(daily_sum_stations['WeekOf']).dt.date\n",
    "    daily_sum_stations = daily_sum_stations[daily_sum_stations.WeekOf.notnull()]\n",
    "    \n",
    "    # get total Traffic (= entries + exits) & place in new 'TotalTraffic' column\n",
    "    daily_sum_stations['TotalTraffic'] = (daily_sum_stations['DAILY_ENTRIES'] \n",
    "                                          + daily_sum_stations['DAILY_EXITS'])\n",
    "    \n",
    "    \n",
    "    return daily_sum_stations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
